Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.
Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError("No module named 'amp_C'")
real 674 fakes 851 mode val
real 2651 fakes 2651 mode train
training epoch 0
D:\University And Papers\VESSL\dfdc_deepfake_challenge\apex\apex\apex\__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)

Epoch 0:   0% 0/10000 [02:52<?, ?it/s, lr=0.01, epoch=0, loss=0.341, fake_loss=0, real_loss=0.681, acc=tensor(0.5000, device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:124: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch 0:   0% 1/10000 [03:10<529:13:40, 190.54s/it, lr=0.01, epoch=0, loss=0.326, fake_loss=0, real_loss=0.651, acc=tensor(0.5000, device='cuda:0')]



Epoch 0:   0% 6/10000 [03:17<33:29:14, 12.06s/it, lr=0.01, epoch=0, loss=0.591, fake_loss=0.58, real_loss=0.602, acc=tensor(0.5714, device='cuda:0')]


Epoch 0:   0% 9/10000 [03:20<12:50:50,  4.63s/it, lr=0.01, epoch=0, loss=0.569, fake_loss=0.629, real_loss=0.509, acc=tensor(0.5500, device='cuda:0')]






Epoch 0:   0% 19/10000 [03:32<3:46:09,  1.36s/it, lr=0.01, epoch=0, loss=0.55, fake_loss=0.73, real_loss=0.37, acc=tensor(0.4737, device='cuda:0')]



































Epoch 0:   1% 75/10000 [04:43<3:27:13,  1.25s/it, lr=0.00999, epoch=0, loss=0.525, fake_loss=0.596, real_loss=0.454, acc=tensor(0.4276, device='cuda:0')]
































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 0:  25% 2454/10000 [55:05<2:30:37,  1.20s/it, lr=0.00978, epoch=0, loss=0.467, fake_loss=0.468, real_loss=0.467, acc=tensor(0.6578, device='cuda:0')]





























Epoch 0:  25% 2500/10000 [56:03<2:30:04,  1.20s/it, lr=0.00978, epoch=0, loss=0.469, fake_loss=0.469, real_loss=0.468, acc=tensor(0.6587, device='cuda:0')]

































































































Epoch 0:  27% 2651/10000 [59:20<2:44:31,  1.34s/it, lr=0.00976, epoch=0, loss=0.46, fake_loss=0.456, real_loss=0.463, acc=tensor(0.6673, device='cuda:0')]
Test phase





























































































































































100%|██████████████████████████████████████████████| 382/382 [06:58<00:00,  1.12s/it]
fake_loss 0.02420261217707931
real_loss 4.169678061391162

100%|██████████████████████████████████████████████| 382/382 [07:00<00:00,  1.10s/it]
Epoch: 0 bce: 2.0969403367841206, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 1

Epoch 1:   0% 0/10000 [00:01<?, ?it/s, lr=0.00976, epoch=1, loss=0.539, fake_loss=0, real_loss=1.08, acc=tensor(0.5000, device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)








































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 1:  20% 2029/10000 [46:49<2:13:48,  1.01s/it, lr=0.00892, epoch=1, loss=0.305, fake_loss=0.259, real_loss=0.351, acc=tensor(0.8512, device='cuda:0')]














































































































































































































Epoch 1:  24% 2397/10000 [53:45<4:51:16,  2.30s/it, lr=0.00888, epoch=1, loss=0.302, fake_loss=0.265, real_loss=0.34, acc=tensor(0.8544, device='cuda:0')]












































































































































































Epoch 1:  27% 2651/10000 [1:00:07<2:46:40,  1.36s/it, lr=0.00886, epoch=1, loss=0.301, fake_loss=0.27, real_loss=0.332, acc=tensor(0.8559, device='cuda:0')]
  0%|                                                        | 0/382 [00:00<?, ?it/s]









































































































100%|██████████████████████████████████████████████| 382/382 [05:22<00:00,  1.18it/s]
fake_loss 0.045954921827631064
real_loss 4.345451116996008
Epoch: 1 bce: 2.1957030194118197, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 2

Epoch 2:   0% 0/10000 [00:01<?, ?it/s, lr=0.00886, epoch=2, loss=0.0581, fake_loss=0.056, real_loss=0.0601, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)











































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 2:  27% 2651/10000 [1:05:10<3:00:40,  1.48s/it, lr=0.00795, epoch=2, loss=0.244, fake_loss=0.244, real_loss=0.243, acc=tensor(0.8923, device='cuda:0')]
Test phase











































































































100%|██████████████████████████████████████████████| 382/382 [04:39<00:00,  1.37it/s]
fake_loss 0.01473435784548547
real_loss 5.004068610926176
Epoch: 2 bce: 2.5094014843858305, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 3
Epoch 3:   0% 0/10000 [00:00<?, ?it/s, lr=0.00795, epoch=3, loss=0.112, fake_loss=0.224, real_loss=0, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 3:  16% 1622/10000 [56:02<2:56:04,  1.26s/it, lr=0.00712, epoch=3, loss=0.226, fake_loss=0.196, real_loss=0.255, acc=tensor(0.9070, device='cuda:0')]









































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 3:  26% 2650/10000 [1:28:10<2:23:03,  1.17s/it, lr=0.00702, epoch=3, loss=0.229, fake_loss=0.207, real_loss=0.251, acc=tensor(0.9057, device='cuda:0')]
Epoch 3:  27% 2651/10000 [1:28:13<4:04:33,  2.00s/it, lr=0.00702, epoch=3, loss=0.229, fake_loss=0.207, real_loss=0.251, acc=tensor(0.9057, device='cuda:0')]

















































































100%|██████████████████████████████████████████████| 382/382 [03:23<00:00,  1.88it/s]
fake_loss 0.010295186655901623
real_loss 5.097377938438985
Epoch: 3 bce: 2.5538365625474433, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 4
Epoch 4:   0% 0/10000 [00:00<?, ?it/s, lr=0.00702, epoch=4, loss=0.0284, fake_loss=0.0568, real_loss=0, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)




























































































































































































































































































































































































































































































































































































Epoch 4:  10% 1015/10000 [19:14<2:16:32,  1.10it/s, lr=0.00624, epoch=4, loss=0.198, fake_loss=0.16, real_loss=0.236, acc=tensor(0.9251, device='cuda:0')]














































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 4:  26% 2582/10000 [1:13:14<4:40:22,  2.27s/it, lr=0.00609, epoch=4, loss=0.201, fake_loss=0.168, real_loss=0.234, acc=tensor(0.9202, device='cuda:0')]













































































Epoch 4:  27% 2651/10000 [1:15:51<3:30:17,  1.72s/it, lr=0.00608, epoch=4, loss=0.202, fake_loss=0.172, real_loss=0.232, acc=tensor(0.9204, device='cuda:0')]
  0%|                                                        | 0/382 [00:00<?, ?it/s]






























































































































































100%|█████████████████████████████████████████████▉| 381/382 [05:47<00:00,  1.19it/s]
fake_loss 0.015422369050765153

100%|██████████████████████████████████████████████| 382/382 [05:48<00:00,  1.10it/s]
Epoch: 4 bce: 2.272717367520937, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 5
Epoch 5:   0% 0/10000 [00:00<?, ?it/s, lr=0.00608, epoch=5, loss=0.0283, fake_loss=0, real_loss=0.0566, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)




































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 5:  27% 2651/10000 [59:12<2:44:07,  1.34s/it, lr=0.00513, epoch=5, loss=0.2, fake_loss=0.183, real_loss=0.217, acc=tensor(0.9249, device='cuda:0')]
Test phase




























































































































































100%|██████████████████████████████████████████████| 382/382 [05:46<00:00,  1.55it/s]
fake_loss 0.020833970018768928
real_loss 4.223924480650961
Epoch: 5 bce: 2.122379225334865, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train

100%|██████████████████████████████████████████████| 382/382 [05:47<00:00,  1.10it/s]
Epoch 6:   0% 0/10000 [00:00<?, ?it/s, lr=0.00513, epoch=6, loss=0.0281, fake_loss=0.0562, real_loss=0, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)



































































































































Epoch 6:   1% 117/10000 [04:26<5:53:07,  2.14s/it, lr=0.0044, epoch=6, loss=0.223, fake_loss=0.151, real_loss=0.295, acc=tensor(0.9060, device='cuda:0')]






















































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 6:  27% 2651/10000 [1:38:32<4:33:11,  2.23s/it, lr=0.00415, epoch=6, loss=0.191, fake_loss=0.183, real_loss=0.198, acc=tensor(0.9272, device='cuda:0')]
  0%|                                                        | 0/382 [00:00<?, ?it/s]




















































































































































100%|██████████████████████████████████████████████| 382/382 [05:51<00:00,  1.09it/s]
fake_loss 0.010461997041614766
real_loss 4.7836815863732625
Epoch: 6 bce: 2.3970717917074387, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 7
Epoch 7:   0% 0/10000 [00:00<?, ?it/s, lr=0.00415, epoch=7, loss=0.0561, fake_loss=0.056, real_loss=0.0562, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)









































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 7:  15% 1514/10000 [55:22<5:09:44,  2.19s/it, lr=0.00327, epoch=7, loss=0.182, fake_loss=0.176, real_loss=0.189, acc=tensor(0.9290, device='cuda:0')]

































































































































































































































































































































































































































































































































































































































































































Epoch 7:  21% 2146/10000 [1:18:27<4:46:17,  2.19s/it, lr=0.0032, epoch=7, loss=0.177, fake_loss=0.178, real_loss=0.175, acc=tensor(0.9324, device='cuda:0')]
























































































































































































































































































































































































































































































































































Epoch 7:  27% 2651/10000 [1:36:53<4:28:37,  2.19s/it, lr=0.00315, epoch=7, loss=0.177, fake_loss=0.173, real_loss=0.181, acc=tensor(0.9338, device='cuda:0')]
Test phase




















































































































































100%|██████████████████████████████████████████████| 382/382 [05:29<00:00,  1.16it/s]
fake_loss 0.011104300748085934
real_loss 4.7667122674216875
Epoch: 7 bce: 2.3889082840848865, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 8
Epoch 8:   0% 0/10000 [00:00<?, ?it/s, lr=0.00315, epoch=8, loss=0.0562, fake_loss=0.0561, real_loss=0.0563, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)































































































































































































































































































































































































































































































Epoch 8:   4% 443/10000 [16:11<5:48:59,  2.19s/it, lr=0.00234, epoch=8, loss=0.157, fake_loss=0.101, real_loss=0.213, acc=tensor(0.9381, device='cuda:0')]


































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 8:  27% 2651/10000 [1:36:33<4:27:41,  2.19s/it, lr=0.00211, epoch=8, loss=0.174, fake_loss=0.144, real_loss=0.203, acc=tensor(0.9381, device='cuda:0')]
Test phase





















































































































































100%|██████████████████████████████████████████████| 382/382 [05:33<00:00,  1.14it/s]
fake_loss 0.01395356324493833
real_loss 4.49796975771093
Epoch: 8 bce: 2.2559616604779342, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 9
Epoch 9:   0% 0/10000 [00:00<?, ?it/s, lr=0.00211, epoch=9, loss=0.0366, fake_loss=0.0732, real_loss=0, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)








































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 9:  26% 2570/10000 [1:33:42<4:15:07,  2.06s/it, lr=0.00102, epoch=9, loss=0.182, fake_loss=0.164, real_loss=0.199, acc=tensor(0.9337, device='cuda:0')]




















































































Epoch 9:  27% 2651/10000 [1:36:40<4:28:00,  2.19s/it, lr=0.00101, epoch=9, loss=0.182, fake_loss=0.166, real_loss=0.198, acc=tensor(0.9338, device='cuda:0')]
  0%|                                                        | 0/382 [00:00<?, ?it/s]




















































































































































100%|██████████████████████████████████████████████| 382/382 [05:29<00:00,  1.16it/s]
fake_loss 0.010686819413094677
real_loss 4.714468792931184
Epoch: 9 bce: 2.362577806172139, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 10
Epoch 10:   0% 0/10000 [00:00<?, ?it/s, lr=0.00101, epoch=10, loss=0.0561, fake_loss=0.0561, real_loss=0.056, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)

























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 10:  27% 2651/10000 [1:36:45<4:28:13,  2.19s/it, lr=0.00981, epoch=10, loss=0.189, fake_loss=0.165, real_loss=0.214, acc=tensor(0.9312, device='cuda:0')]
  0%|                                                        | 0/382 [00:00<?, ?it/s]




















































































































































 99%|█████████████████████████████████████████████▊| 380/382 [05:33<00:01,  1.28it/s]
fake_loss 0.021044045188468526

100%|██████████████████████████████████████████████| 382/382 [05:35<00:00,  1.14it/s]
Epoch: 10 bce: 2.161475684870002, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 11
Epoch 11:   0% 0/10000 [00:00<?, ?it/s, lr=0.00981, epoch=11, loss=0.369, fake_loss=0.675, real_loss=0.0634, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 11:  22% 2166/10000 [1:19:05<4:45:51,  2.19s/it, lr=0.00895, epoch=11, loss=0.187, fake_loss=0.172, real_loss=0.201, acc=tensor(0.9262, device='cuda:0')]








































































































































































































































































































































































































































































































































Epoch 11:  27% 2651/10000 [1:36:48<4:28:22,  2.19s/it, lr=0.0089, epoch=11, loss=0.183, fake_loss=0.168, real_loss=0.199, acc=tensor(0.9283, device='cuda:0')]
Test phase




















































































































































100%|██████████████████████████████████████████████| 382/382 [06:07<00:00,  1.04it/s]
fake_loss 0.018032601932660652
real_loss 4.201633376658687
Epoch: 11 bce: 2.1098329892956738, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 12

Epoch 12:   0% 0/10000 [00:02<?, ?it/s, lr=0.0089, epoch=12, loss=0.0562, fake_loss=0.0561, real_loss=0.0563, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)













































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 12:  20% 1971/10000 [1:11:58<4:52:52,  2.19s/it, lr=0.00805, epoch=12, loss=0.192, fake_loss=0.171, real_loss=0.213, acc=tensor(0.9298, device='cuda:0')]

























































































































































































































































































































































































































































Epoch 12:  24% 2383/10000 [1:26:59<4:37:39,  2.19s/it, lr=0.00802, epoch=12, loss=0.191, fake_loss=0.17, real_loss=0.211, acc=tensor(0.9301, device='cuda:0')]































































































































































































































































































Epoch 12:  27% 2651/10000 [1:36:46<4:30:02,  2.20s/it, lr=0.00799, epoch=12, loss=0.193, fake_loss=0.17, real_loss=0.217, acc=tensor(0.9298, device='cuda:0')]
Epoch 12:  27% 2651/10000 [1:36:46<4:28:17,  2.19s/it, lr=0.00799, epoch=12, loss=0.193, fake_loss=0.17, real_loss=0.217, acc=tensor(0.9298, device='cuda:0')]




















































































































































 99%|█████████████████████████████████████████████▊| 380/382 [05:31<00:01,  1.29it/s]
fake_loss 0.0070777401301757225

100%|██████████████████████████████████████████████| 382/382 [05:33<00:00,  1.14it/s]
Epoch: 12 bce: 2.588186057244771, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 13

Epoch 13:   0% 0/10000 [00:00<?, ?it/s, lr=0.00799, epoch=13, loss=0.891, fake_loss=0, real_loss=1.78, acc=tensor(0.5000, device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)





































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 13:  27% 2651/10000 [1:36:41<4:28:03,  2.19s/it, lr=0.00707, epoch=13, loss=0.175, fake_loss=0.165, real_loss=0.186, acc=tensor(0.9381, device='cuda:0')]
  0%|                                                        | 0/382 [00:00<?, ?it/s]




















































































































































 99%|█████████████████████████████████████████████▊| 380/382 [05:27<00:01,  1.29it/s]
fake_loss 0.017007648028913094
real_loss 5.38983492088579
Epoch: 13 bce: 2.7034212844573515, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train

100%|██████████████████████████████████████████████| 382/382 [05:28<00:00,  1.16it/s]

Epoch 14:   0% 0/10000 [00:00<?, ?it/s, lr=0.00707, epoch=14, loss=0.056, fake_loss=0.056, real_loss=0.056, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 14:  23% 2326/10000 [1:24:56<4:41:53,  2.20s/it, lr=0.00616, epoch=14, loss=0.18, fake_loss=0.167, real_loss=0.193, acc=tensor(0.9388, device='cuda:0')]































































































































































































































































Epoch 14:  27% 2651/10000 [1:36:48<4:28:21,  2.19s/it, lr=0.00613, epoch=14, loss=0.177, fake_loss=0.165, real_loss=0.19, acc=tensor(0.9395, device='cuda:0')]
  0%|                                                        | 0/382 [00:00<?, ?it/s]














100%|██████████████████████████████████████████████| 382/382 [05:54<00:00,  1.08it/s]
fake_loss 0.009116034635219452
real_loss 4.90025012073519
Epoch: 14 bce: 2.4546830776852047, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 15
Epoch 15:   0% 0/10000 [00:00<?, ?it/s, lr=0.00613, epoch=15, loss=1.22, fake_loss=0, real_loss=2.43, acc=tensor(0.5000, device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)








































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 15:  19% 1910/10000 [1:09:45<4:54:32,  2.18s/it, lr=0.00525, epoch=15, loss=0.161, fake_loss=0.148, real_loss=0.173, acc=tensor(0.9419, device='cuda:0')]
















































































































































































































































































































































































































































































































































































































































































































































































































Epoch 15:  27% 2651/10000 [1:36:39<4:27:57,  2.19s/it, lr=0.00518, epoch=15, loss=0.165, fake_loss=0.152, real_loss=0.178, acc=tensor(0.9406, device='cuda:0')]
  0%|                                                        | 0/382 [00:00<?, ?it/s]


















































































































































 99%|█████████████████████████████████████████████▋| 379/382 [05:23<00:02,  1.29it/s]
fake_loss 0.008637917748587048

100%|██████████████████████████████████████████████| 382/382 [05:26<00:00,  1.17it/s]
Epoch: 15 bce: 2.588411095108253, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 16
Epoch 16:   0% 0/10000 [00:00<?, ?it/s, lr=0.00518, epoch=16, loss=0.0561, fake_loss=0.056, real_loss=0.0562, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)







































































































































































































































































































































































































































































































































































































































































































Epoch 16:  10% 962/10000 [22:55<2:19:00,  1.08it/s, lr=0.00437, epoch=16, loss=0.166, fake_loss=0.136, real_loss=0.195, acc=tensor(0.9398, device='cuda:0')]






























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 16:  27% 2651/10000 [1:07:16<3:06:29,  1.52s/it, lr=0.0042, epoch=16, loss=0.157, fake_loss=0.14, real_loss=0.174, acc=tensor(0.9461, device='cuda:0')]
Test phase




































































































































































100%|██████████████████████████████████████████████| 382/382 [06:11<00:00,  1.03it/s]
fake_loss 0.017037725336770337
real_loss 4.435018385412458
Epoch: 16 bce: 2.226028055374614, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 17
Epoch 17:   0% 0/10000 [00:00<?, ?it/s, lr=0.0042, epoch=17, loss=0.029, fake_loss=0, real_loss=0.0581, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)







































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 17:  27% 2651/10000 [44:31<2:03:26,  1.01s/it, lr=0.0032, epoch=17, loss=0.161, fake_loss=0.139, real_loss=0.182, acc=tensor(0.9445, device='cuda:0')]
  0%|                                                        | 0/382 [00:00<?, ?it/s]






























































100%|██████████████████████████████████████████████| 382/382 [02:37<00:00,  2.43it/s]
fake_loss 0.01947865038702328
real_loss 5.093254201386832
Epoch: 17 bce: 2.5563664258869276, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 18
Epoch 18:   0% 0/10000 [00:00<?, ?it/s, lr=0.0032, epoch=18, loss=0.0564, fake_loss=0.0561, real_loss=0.0568, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)


Epoch 18:   0% 4/10000 [00:05<3:10:35,  1.14s/it, lr=0.00244, epoch=18, loss=0.114, fake_loss=0.182, real_loss=0.0454, acc=tensor(0.9000, device='cuda:0')]

























































































































































































































































































































































































































































Epoch 18:  10% 968/10000 [14:51<2:30:35,  1.00s/it, lr=0.00234, epoch=18, loss=0.169, fake_loss=0.135, real_loss=0.202, acc=tensor(0.9432, device='cuda:0')]
























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 18:  27% 2651/10000 [47:52<2:12:43,  1.08s/it, lr=0.00216, epoch=18, loss=0.157, fake_loss=0.131, real_loss=0.184, acc=tensor(0.9449, device='cuda:0')]
Test phase



















































100%|██████████████████████████████████████████████| 382/382 [02:14<00:00,  2.84it/s]
fake_loss 0.024643383920888644
real_loss 4.670374252210385
Epoch: 18 bce: 2.347508818065637, bce_best: 2.0969403367841206
real 2651 fakes 2651 mode train
training epoch 19
Epoch 19:   0% 0/10000 [00:00<?, ?it/s, lr=0.00216, epoch=19, loss=0.0282, fake_loss=0.0563, real_loss=0, acc=tensor(1., device='cuda:0')]D:\APPs\Anaconda\lib\site-packages\torch\optim\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)




























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 19:  27% 2651/10000 [48:32<2:14:33,  1.10s/it, lr=0.00107, epoch=19, loss=0.15, fake_loss=0.135, real_loss=0.165, acc=tensor(0.9483, device='cuda:0')]
  0%|                                                        | 0/382 [00:00<?, ?it/s]


































































































































































100%|██████████████████████████████████████████████| 382/382 [05:56<00:00,  1.47it/s]
fake_loss 0.02140976176648068

100%|██████████████████████████████████████████████| 382/382 [05:57<00:00,  1.07it/s]
Epoch: 19 bce: 2.5226310645526953, bce_best: 2.0969403367841206